{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4f2onCOj0iGHKarbk0lwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimHyeongSoo/Choong-Ang_Final_Capstone_CVProject_Andrew/blob/main/%08CV_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WDZk__BAn1Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 라이브러리 import"
      ],
      "metadata": {
        "id": "qJzLYrxgoglm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install git+https://github.com/ultralytics/yolov5\n",
        "!pip install ultralytics\n",
        "!pip install transformers torch torchvision"
      ],
      "metadata": {
        "id": "h4sR06dXogA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 검출 훈련(자동차 or 버스)"
      ],
      "metadata": {
        "id": "IKbkVYmLomcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-4X9qxYnn9l"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "class YOLOv8Model:\n",
        "    def __init__(self, model_path=None):\n",
        "        if model_path is not None:\n",
        "            self.model = YOLO(weights=model_path)\n",
        "        else:\n",
        "            self.model = YOLO()\n",
        "\n",
        "    def load_dataset(self, dataset_path):\n",
        "        \"\"\"데이터셋 로드\"\"\"\n",
        "        self.model.dataset(dataset_path)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"모델 훈련 시작\"\"\"\n",
        "        self.model.fit()\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        \"\"\"훈련된 모델 저장\"\"\"\n",
        "        self.model.save(save_path)\n",
        "\n",
        "    def detect(self, image_path):\n",
        "        \"\"\"이미지에서 객체 검출\"\"\"\n",
        "        results = self.model(image_path)\n",
        "        results.show()\n",
        "        return results\n",
        "\n",
        "# 사용\n",
        "if __name__ == \"__main__\":\n",
        "    # 모델 훈련\n",
        "    trainer = YOLOv8Model()\n",
        "    trainer.load_dataset('/content/drive/MyDrive/졸업논문_자율주행자동차/Dataset.yaml')\n",
        "    trainer.train()\n",
        "    trainer.save_model('/content/drive/MyDrive/졸업논문_자율주행자동차/model.pt')\n",
        "\n",
        "    # 훈련된 모델 로드 및 객체 검출\n",
        "    detector = YOLOv8Model(model_path='/content/drive/MyDrive/졸업논문_자율주행자동차/model.pt')\n",
        "    detection_results = detector.detect('/content/drive/MyDrive/졸업논문_자율주행자동차/image.jpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 차선 검출 & 방향성(각도 검출)"
      ],
      "metadata": {
        "id": "K4rdflMUorsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class DeepLabLaneDetector:\n",
        "    def __init__(self, model_path):\n",
        "        \"\"\"모델 초기화 및 로드\"\"\"\n",
        "        self.model = tf.saved_model.load(model_path)\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"이미지에서 차선과 객체를 검출\"\"\"\n",
        "        image = tf.io.read_file(image_path)\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "        image = tf.image.resize(image, [513, 513])\n",
        "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
        "        batch_image = tf.expand_dims(image, 0)\n",
        "\n",
        "        # 모델 예측\n",
        "        output = self.model(batch_image)\n",
        "        logits = output['logits']\n",
        "        semantic_prediction = tf.argmax(logits, axis=-1)\n",
        "        semantic_prediction = tf.squeeze(semantic_prediction).numpy()\n",
        "\n",
        "        return semantic_prediction, image.numpy()\n",
        "\n",
        "    def detect_lines(self, image):\n",
        "        \"\"\"이미지에서 선을 검출하기 위해 Hough 변환 사용\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
        "        return lines\n",
        "\n",
        "    def calculate_lane_orientation(self, lines):\n",
        "        \"\"\"검출된 선으로부터 차선의 방향성 계산\"\"\"\n",
        "        if lines is not None:\n",
        "            line = lines[0]  # 대표 선을 사용\n",
        "            orientation = np.arctan2(line[1] - line[3], line[0] - line[2]) * 180 / np.pi\n",
        "            return orientation\n",
        "        return None\n",
        "\n",
        "    def visualize(self, image, prediction):\n",
        "        \"\"\"검출 결과 시각화\"\"\"\n",
        "        colored_prediction = np.zeros_like(image)\n",
        "        colored_prediction[prediction == 1] = [255, 0, 0]  # 차선을 빨간색으로 표시\n",
        "        colored_image = cv2.addWeighted(image, 0.5, colored_prediction, 0.5, 0)\n",
        "        cv2.imshow('Lane Detection', colored_image)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    detector = DeepLabLaneDetector('/content/drive/MyDrive/졸업논문_자율주행자동차/deeplab (1)/model')\n",
        "    prediction, original_image = detector.predict('/content/drive/MyDrive/졸업논문_자율주행자동차/deeplab (1)/image.png')\n",
        "    lines_detected = detector.detect_lines((original_image * 127.5 + 127.5).astype(np.uint8))\n",
        "    lane_orientation = detector.calculate_lane_orientation(lines_detected)\n",
        "    detector.visualize(original_image, prediction)\n",
        "    print(f\"Lane Orientation: {lane_orientation} degrees\")\n"
      ],
      "metadata": {
        "id": "bxh7WxAQoX1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 도로 구조물 종류 검출(우선 clip을 이용하여 도로 구조물 분류 작업)"
      ],
      "metadata": {
        "id": "YMhtkj_0qwao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "class CLIPRoadStructureDetector:\n",
        "    def __init__(self, model_name=\"openai/clip-vit-base-patch32\"):\n",
        "        \"\"\"모델과 프로세서 초기화\"\"\"\n",
        "        self.model = CLIPModel.from_pretrained(model_name)\n",
        "        self.processor = CLIPProcessor.from_pretrained(model_name)\n",
        "\n",
        "    def load_prompts(self, file_path):\n",
        "        \"\"\"프롬프트 파일 로드\"\"\"\n",
        "        with open(file_path, 'r') as file:\n",
        "            prompts = [line.strip() for line in file if line.strip()]\n",
        "        return prompts\n",
        "\n",
        "    def detect_structure(self, image_url, prompts_file):\n",
        "        \"\"\"이미지에서 도로 구조물 검출\"\"\"\n",
        "        # 이미지 로드\n",
        "        response = requests.get(image_url)\n",
        "        pil_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "        # 프롬프트 로드\n",
        "        prompts = self.load_prompts(prompts_file)\n",
        "\n",
        "        # 입력 처리 및 모델 실행\n",
        "        inputs = self.processor(text=prompts, images=pil_image, return_tensors=\"pt\", padding=True)\n",
        "        outputs = self.model(**inputs)\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "        probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "        # 가장 높은 점수와 해당 프롬프트 출력\n",
        "        max_index = probs.argmax()\n",
        "        best_prompt = prompts[max_index]\n",
        "        best_score = probs[0, max_index].item()  # 확률 점수\n",
        "\n",
        "        return best_prompt, best_score\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    detector = CLIPRoadStructureDetector()\n",
        "    best_match, score = detector.detect_structure(\"/content/drive/MyDrive/졸업논문_자율주행자동차/structure/test.jpg\", \"/content/drive/MyDrive/졸업논문_자율주행자동차/structure/prompts.txt\")\n",
        "    print(f\"Best match: {best_match} with a score of {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "TVlKJ3Xdqbq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}